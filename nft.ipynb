{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "#nltk.download() #only for the first time running it\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import regex as re\n",
    "from textblob import TextBlob\n",
    "import numpy\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import igraph\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe on media posts USE FOR ALL DATA - Don't run now\n",
    "def createDataFrame():  \n",
    "    with open(\"datain/nft_search_tweets_sample.jsonl\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            row = json.loads(line)\n",
    "            try:\n",
    "                if row[\"lang\"] == 'en' and len(row.get('referenced_tweets', [])) == 0 and len(row.get('entities', ['hashtags'])) != 0:\n",
    "                    yield (row['id'],\n",
    "                            row['text'],\n",
    "                            row['entities']['hashtags'],\n",
    "                            row['public_metrics']['retweet_count'],\n",
    "                            row['public_metrics']['quote_count'],\n",
    "                            row['public_metrics']['reply_count'],\n",
    "                            row['public_metrics']['like_count'],\n",
    "                            row['attachments']['media_keys'])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "#create csv\n",
    "df = pd.DataFrame(createDataFrame())\n",
    "df.columns =['id', 'text', 'hashtags', 'retweet_count', 'quote_count', 'reply_count', 'like_count', 'media_keys']\n",
    "df.to_json('datain/nft_tweets.jsonl', orient='records', index=True, lines= True)\n",
    "output = pd.read_json(\"datain/nft_tweets.jsonl\", lines = True)\n",
    "output['total'] = output[['retweet_count', 'quote_count','reply_count', 'like_count']].sum(axis=1)\n",
    "#sort by highest total\n",
    "output = output.sort_values(by = 'total', ascending = False)\n",
    "#top 100\n",
    "output = output.head(100)\n",
    "output.to_json('datain/nft_top_100_tweets.jsonl', orient='records', index=True, lines= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "data = pd.read_json(\"datain/nft_top_100_tweets.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_json(\"datain/nft_search_tweets_sample.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('rt')\n",
    "stop_words.append('nft')\n",
    "# stop_words.append('#nft')\n",
    "\n",
    "#function for cleaning a tweet (remove mentions, hashtags, links, html entities, stop words. And make sure it's only letters)\n",
    "def clean_tweet(tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        tweet = str.lower(tweet)\n",
    "        # tweet = ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|(#[A-Za-z0-9_]+)\", \" \", tweet).split()) # remove mentions and hashtags\n",
    "        # tweet = ' '.join(re.sub(\"(@[A-Za-z0-9_]+)\", \" \", tweet).split())\n",
    "        tweet = re.sub(\"(http\\S+|http)\", \"\", tweet, flags=re.MULTILINE) # remove links\n",
    "        tweet = re.sub('\\&\\w+', \"\", tweet) # remove html entities\n",
    "        tweet = re.sub('[^a-zA-Z# ]+', ' ', tweet) # make sure tweet is only letters\n",
    "        # stem & remove stop words\n",
    "        # tweet = ' '.join([PorterStemmer().stem(word=word) for word in tweet.split() if word not in stop_words])\n",
    "        tweet = ' '.join([word for word in tweet.split() if word not in stop_words])\n",
    "        return tweet\n",
    "\n",
    "#clean data\n",
    "for i in sample_data.index:\n",
    "    text = sample_data[\"text\"][i]\n",
    "    cleaned_text = clean_tweet(text)\n",
    "    cleaned_text = html.unescape(cleaned_text)\n",
    "    sample_data[\"text\"][i] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.to_json('datain/nft_search_tweets_sample_cleaned.jsonl', orient='records', index=True, lines= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = sample_data['text'].str.cat(sep=' ')\n",
    "tokens = nltk.word_tokenize(tweet_text)\n",
    "most_common = pd.DataFrame(nltk.ngrams(tokens, 1)).value_counts().to_frame()\n",
    "# terms_count = term_data['text'].value_counts().to_dict()\n",
    "# terms_count = pd.DataFrame.from_dict(terms_count, orient='index')\n",
    "\n",
    "# terms_count.to_html(\"dataout/terms_count.html\")\n",
    "\n",
    "most_common.to_html('dataout/term_freq.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nft_top_100_sentiment <- Has interactions and sentiment totals\n",
    "positivity = ''\n",
    "output = pd.read_json(\"datain/nft_top_100_cleaned_interactions.jsonl\", lines = True)\n",
    "def getSentiment():\n",
    "    for i in output.index:\n",
    "        row = TextBlob(output.iloc[i]['text'])\n",
    "        if row.sentiment.polarity >= 0.7:\n",
    "                positivity = 'mostly_positive'\n",
    "        elif row.sentiment.polarity <= -0.7:\n",
    "            positivity = 'mostly_negative'\n",
    "        elif row.sentiment.polarity > -0.7 and row.sentiment.polarity < -0.4:\n",
    "            positivity = 'negative'\n",
    "        elif row.sentiment.polarity > 0.4 and row.sentiment.polarity < 0.7:\n",
    "                positivity = 'positive'\n",
    "        else:\n",
    "            positivity = 'nuetral'\n",
    "        yield  row.sentiment.polarity, row.sentiment.subjectivity, positivity\n",
    "        \n",
    "df = pd.DataFrame(getSentiment())\n",
    "df.columns =['polarity', 'subjectivity', 'positivity']\n",
    "output['polarity'] = df['polarity']\n",
    "output['subjectivity'] = df['subjectivity']\n",
    "output['positivity'] = df['positivity']\n",
    "output.to_json('datain/nft_top_100_cleaned_interactions_sentiment.jsonl', orient='records', index=True, lines= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud of top 100 NFT's\n",
    "top_100_word_cloud = pd.read_json(\"datain/nft_top_100_cleaned_interactions_sentiment.jsonl\", lines=True)\n",
    "# Generate a word cloud image\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update((\"t\", \"co\", \"https\", \"t\", \"amp\", \"RT\"))\n",
    "wordcloud = WordCloud(stopwords=stopwords,background_color='white', max_words=1000,contour_color='#023075',contour_width=3,colormap='rainbow').generate(' '.join(top_100_word_cloud['text']))\n",
    "# create image as cloud\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "# store to file\n",
    "plt.savefig(\"cloud.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment sentiment\n",
    "#### Read from nft_search_tweets_sample - need replied to with text and author\n",
    "#### Original Poster\n",
    "def createOriginalDataFrame():  \n",
    "    with open(\"datain/nft_search_tweets_sample.jsonl\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            row = json.loads(line)\n",
    "            try:\n",
    "                if row[\"lang\"] == 'en'and len(row.get('referenced_tweets', [])) == 0:\n",
    "                    yield (row['id'],\n",
    "                            row['text'],\n",
    "                            row['author_id'],\n",
    "                            row['public_metrics']['retweet_count'],\n",
    "                            row['public_metrics']['quote_count'],\n",
    "                            row['public_metrics']['reply_count'],\n",
    "                            row['public_metrics']['like_count'],\n",
    "                            row['attachments']['media_keys'],\n",
    "                            row['created_at']\n",
    "                    )\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "def createRepliesDataFrame():  \n",
    "    with open(\"datain/nft_search_tweets_sample.jsonl\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            row = json.loads(line)\n",
    "            try:\n",
    "                if row[\"lang\"] == 'en'and len(row.get('referenced_tweets', [])) != 0:\n",
    "                    yield (row['id'],\n",
    "                            row['text'],\n",
    "                            row['author_id'],\n",
    "                            row['in_reply_to_user_id'],\n",
    "                            row['public_metrics']['retweet_count'],\n",
    "                            row['public_metrics']['quote_count'],\n",
    "                            row['public_metrics']['reply_count'],\n",
    "                            row['public_metrics']['like_count'],\n",
    "                            row['attachments']['media_keys'],\n",
    "                            row['created_at']\n",
    "                    )\n",
    "            except KeyError:\n",
    "                pass\n",
    "#create csv\n",
    "original_data = pd.DataFrame(createOriginalDataFrame())\n",
    "original_data.columns =['id', 'text', 'in_reply_to_user_id', 'retweet_count', 'quote_count', 'reply_count', 'like_count', 'media_keys', 'created_at']\n",
    "original_data.to_json('datain/nft_original_tweets.jsonl', orient='records', index=True, lines= True)\n",
    "original_data['total'] = original_data[['retweet_count', 'quote_count','reply_count', 'like_count']].sum(axis=1)\n",
    "\n",
    "replies_data = pd.DataFrame(createRepliesDataFrame())\n",
    "replies_data.columns =['id', 'text', 'reply_author_id', 'in_reply_to_user_id', 'retweet_count', 'quote_count', 'reply_count', 'like_count', 'media_keys', 'created_at']\n",
    "replies_data.to_json('datain/nft_replies_tweets.jsonl', orient='records', index=True, lines= True)\n",
    "replies_data['total'] = replies_data[['retweet_count', 'quote_count','reply_count', 'like_count']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.reindex()\n",
    "replies_data.reindex()\n",
    "\n",
    "all_data = pd.merge(original_data, replies_data, on='in_reply_to_user_id').dropna()\n",
    "\n",
    "# replies_data['matched_id'] = pd.Series((original_data.original_author_id.isin(replies_data.reply_author_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment():\n",
    "    for i in all_data.index:\n",
    "        row = TextBlob(all_data.iloc[i]['text_y'])\n",
    "        if row.sentiment.polarity >= 0.7:\n",
    "                positivity = 'mostly_positive'\n",
    "        elif row.sentiment.polarity <= -0.7:\n",
    "            positivity = 'mostly_negative'\n",
    "        elif row.sentiment.polarity > -0.7 and row.sentiment.polarity < -0.4:\n",
    "            positivity = 'negative'\n",
    "        elif row.sentiment.polarity > 0.4 and row.sentiment.polarity < 0.7:\n",
    "                positivity = 'positive'\n",
    "        else:\n",
    "            positivity = 'nuetral'\n",
    "        yield  row.sentiment.polarity, row.sentiment.subjectivity, positivity\n",
    "    # with open(\"datain/cleaned.txt\", encoding='utf8') as f:\n",
    "    #     for line in f:\n",
    "    #         row = TextBlob(line)\n",
    "    #         if row.sentiment.polarity >= 0.7:\n",
    "    #             positivity = 'mostly_positive'\n",
    "    #         elif row.sentiment.polarity <= -0.7:\n",
    "    #             positivity = 'mostly_negative'\n",
    "    #         elif row.sentiment.polarity > -0.7 and row.sentiment.polarity < -0.4:\n",
    "    #             positivity = 'negative'\n",
    "    #         elif row.sentiment.polarity > 0.4 and row.sentiment.polarity < 0.7:\n",
    "    #              positivity = 'positive'\n",
    "    #         else:\n",
    "    #             positivity = 'nuetral'\n",
    "    #         yield line, row.sentiment.polarity, row.sentiment.subjectivity, positivity\n",
    "\n",
    "df = pd.DataFrame(getSentiment())\n",
    "df.columns =['polarity', 'subjectivity', 'positivity']\n",
    "all_data['polarity'] = df['polarity']\n",
    "all_data['subjectivity'] = df['subjectivity']\n",
    "all_data['positivity'] = df['positivity']\n",
    "all_data.to_json('datain/matched_author_replied_sentiment.jsonl', orient='records', index=True, lines= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTagDataFrame():  \n",
    "    with open(\"datain/nft_search_tweets_sample.jsonl\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            row = json.loads(line)\n",
    "            try:\n",
    "                if row[\"lang\"] == 'en' and len(row.get('entities', ['hashtags'])) != 0:\n",
    "                    yield (row['id'],\n",
    "                            row['text'],\n",
    "                            row['entities']['hashtags'])\n",
    "            except KeyError:\n",
    "                pass\n",
    "#create csv\n",
    "tag_data = pd.DataFrame(createTagDataFrame())\n",
    "tag_data.columns =['id', 'text', 'hashtags']\n",
    "new_df = pd.concat([pd.DataFrame(pd.json_normalize(x)) for x in tag_data['hashtags']],ignore_index=True)\n",
    "\n",
    "tags_count = new_df['tag'].value_counts().to_dict()\n",
    "counts = pd.DataFrame.from_dict(tags_count, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_count.to_html(\"dataout/tags_count.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_sentiment_df = pd.read_json('datain/matched_author_replied_sentiment.jsonl', lines=True)\n",
    "interactions_sentiment_df['created_at_x'] = interactions_sentiment_df['created_at_x'].astype('datetime64[ns]')\n",
    "interactions_sentiment_df['created_at_y'] = interactions_sentiment_df['created_at_y'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactions vs time\n",
    "interactions_sentiment_df.sort_values(by = 'created_at_x', ascending = False)\n",
    "plt.bar(interactions_sentiment_df['created_at_x'].dt.hour, interactions_sentiment_df['total_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node user\n",
    "#Edge from - to.\n",
    "# all_data['id_x']\n",
    "\n",
    "# all_data['id_y']\n",
    "\n",
    "G = nx.from_pandas_edgelist(all_data, 'id_y', 'id_x') #Turn df into graph\n",
    "pos = nx.spring_layout(G) #specify layout for visual\n",
    "\n",
    "f, ax = plt.subplots(figsize=(50, 50))\n",
    "plt.style.use('ggplot')\n",
    "nodes = nx.draw_networkx_nodes(G, pos,\n",
    "                               alpha=0.8)\n",
    "nodes.set_edgecolor('k')\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'ycorr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-15c8fb63aba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msentiment_vs_interactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datain/nft_top_100_cleaned_interactions_sentiment.jsonl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mycorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_vs_interactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'polarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment_vs_interactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musevlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sentiment vs Total Interactions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'ycorr'"
     ]
    }
   ],
   "source": [
    "#total vs polarity corr\n",
    "sentiment_vs_interactions = pd.read_json('datain/nft_top_100_cleaned_interactions_sentiment.jsonl', lines=True)\n",
    "\n",
    "lines = plt.xcorr(sentiment_vs_interactions['polarity'], sentiment_vs_interactions['total'], maxlags=9, usevlines=True)\n",
    "\n",
    "plt.title('Sentiment vs Total Interactions')\n",
    "\n",
    "plt.xlabel('Sentiment')\n",
    "\n",
    "plt.ylabel('Interactions')    \n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.axhline(0, color='red', lw=2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Does this mean no correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds the title\n",
    "plt.title('Correlation between Polarity and Interactions')\n",
    "  \n",
    "# plot the data\n",
    "plt.scatter(sentiment_vs_interactions['total'], sentiment_vs_interactions['polarity'])\n",
    "  \n",
    "# fits the best fitting line to the data\n",
    "plt.xcorr(sentiment_vs_interactions['total'], sentiment_vs_interactions['polarity'])\n",
    "  \n",
    "# Labelling axes\n",
    "plt.xlabel('interactions')\n",
    "plt.ylabel('polarity')\n",
    "\n",
    "sentiment_vs_interactions[\"total\"].corr(sentiment_vs_interactions[\"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>media_keys</th>\n",
       "      <th>total</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1369983392155009024</td>\n",
       "      <td>celebrating lilmoon rockets reveal giveway wor...</td>\n",
       "      <td>917</td>\n",
       "      <td>186</td>\n",
       "      <td>1920</td>\n",
       "      <td>1076</td>\n",
       "      <td>[3_1369983389210710019]</td>\n",
       "      <td>4099</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>...</td>\n",
       "      <td>BinanceSmartChain</td>\n",
       "      <td>BNB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1395797789662187520</td>\n",
       "      <td>fleek officially running allowing dapps run we...</td>\n",
       "      <td>820</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>2522</td>\n",
       "      <td>[3_1395783651007377411]</td>\n",
       "      <td>3421</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1393223147630075904</td>\n",
       "      <td>sft live ready trade mcap circ supply price ac...</td>\n",
       "      <td>1545</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>865</td>\n",
       "      <td>[3_1393223052079546377]</td>\n",
       "      <td>2420</td>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1375754272437116928</td>\n",
       "      <td>let knock nfts head want revenge please watch ...</td>\n",
       "      <td>762</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>1326</td>\n",
       "      <td>[7_1375754125414166528]</td>\n",
       "      <td>2162</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1380255678925742080</td>\n",
       "      <td>new drop coming tomorrow stay tuned</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1836</td>\n",
       "      <td>[3_1380255253862379521]</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1369447537111875584</td>\n",
       "      <td>play cards right audio experience available et...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>[7_1369447396887891972]</td>\n",
       "      <td>156</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1374851744157605888</td>\n",
       "      <td>know dropping one tomorrow single edition</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>[3_1374851735928377349]</td>\n",
       "      <td>154</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1383371108137668608</td>\n",
       "      <td>rainbow part rainbow series eth</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>125</td>\n",
       "      <td>[3_1383369061678010374, 3_1383370426395500556]</td>\n",
       "      <td>151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1378962295171117056</td>\n",
       "      <td>night show got</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>[16_1378962285079621635]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1388124885944311808</td>\n",
       "      <td>wanderer genesis piece available eth let guide...</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>[7_1388123245895987207]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>nftcollector</td>\n",
       "      <td>nftcollectors</td>\n",
       "      <td>nftart</td>\n",
       "      <td>glitch</td>\n",
       "      <td>NFTCommunity</td>\n",
       "      <td>Cryptoart</td>\n",
       "      <td>NFTartist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1369983392155009024  celebrating lilmoon rockets reveal giveway wor...   \n",
       "1   1395797789662187520  fleek officially running allowing dapps run we...   \n",
       "2   1393223147630075904  sft live ready trade mcap circ supply price ac...   \n",
       "3   1375754272437116928  let knock nfts head want revenge please watch ...   \n",
       "4   1380255678925742080                new drop coming tomorrow stay tuned   \n",
       "..                  ...                                                ...   \n",
       "95  1369447537111875584  play cards right audio experience available et...   \n",
       "96  1374851744157605888          know dropping one tomorrow single edition   \n",
       "97  1383371108137668608                    rainbow part rainbow series eth   \n",
       "98  1378962295171117056                                     night show got   \n",
       "99  1388124885944311808  wanderer genesis piece available eth let guide...   \n",
       "\n",
       "    retweet_count  quote_count  reply_count  like_count  \\\n",
       "0             917          186         1920        1076   \n",
       "1             820           22           57        2522   \n",
       "2            1545            5            5         865   \n",
       "3             762           48           26        1326   \n",
       "4              97            7           35        1836   \n",
       "..            ...          ...          ...         ...   \n",
       "95             36            4           15         101   \n",
       "96              7            1           16         130   \n",
       "97             15            2            9         125   \n",
       "98              8            0           76          66   \n",
       "99             47            2            1         100   \n",
       "\n",
       "                                        media_keys  total  polarity  \\\n",
       "0                          [3_1369983389210710019]   4099  0.311111   \n",
       "1                          [3_1395783651007377411]   3421  0.083333   \n",
       "2                          [3_1393223052079546377]   2420  0.067677   \n",
       "3                          [7_1375754125414166528]   2162  0.212500   \n",
       "4                          [3_1380255253862379521]   1975  0.136364   \n",
       "..                                             ...    ...       ...   \n",
       "95                         [7_1369447396887891972]    156  0.228571   \n",
       "96                         [3_1374851735928377349]    154 -0.071429   \n",
       "97  [3_1383369061678010374, 3_1383370426395500556]    151  0.000000   \n",
       "98                        [16_1378962285079621635]    150  0.000000   \n",
       "99                         [7_1388123245895987207]    150  0.400000   \n",
       "\n",
       "    subjectivity  ...                tag            tag     tag     tag  \\\n",
       "0       0.344444  ...  BinanceSmartChain            BNB     NaN     NaN   \n",
       "1       0.583333  ...                NaN            NaN     NaN     NaN   \n",
       "2       0.533333  ...                NaN            NaN     NaN     NaN   \n",
       "3       0.550000  ...                NaN            NaN     NaN     NaN   \n",
       "4       0.454545  ...                NaN            NaN     NaN     NaN   \n",
       "..           ...  ...                ...            ...     ...     ...   \n",
       "95      0.645238  ...                NaN            NaN     NaN     NaN   \n",
       "96      0.214286  ...           Ethereum        bitcoin     NaN     NaN   \n",
       "97      0.000000  ...                NaN            NaN     NaN     NaN   \n",
       "98      0.000000  ...                NaN            NaN     NaN     NaN   \n",
       "99      0.400000  ...       nftcollector  nftcollectors  nftart  glitch   \n",
       "\n",
       "             tag        tag        tag  tag  tag  tag  \n",
       "0            NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "1            NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "2            NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "3            NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "4            NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "..           ...        ...        ...  ...  ...  ...  \n",
       "95           NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "96           NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "97           NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "98           NaN        NaN        NaN  NaN  NaN  NaN  \n",
       "99  NFTCommunity  Cryptoart  NFTartist  NaN  NaN  NaN  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expected = pd.concat([sentiment_vs_interactions, sentiment_vs_interactions['hashtags'].apply(pd.Series)], axis = 1).drop('hashtags', axis = 1)\n",
    "\n",
    "for i in range(13):\n",
    "    df_expected = pd.concat([df_expected, df_expected[i].apply(pd.Series)], axis = 1).drop([i, 0, 'start', 'end'], axis = 1)\n",
    "\n",
    "df_expected"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
